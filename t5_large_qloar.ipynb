{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T23:26:47.910891Z",
     "start_time": "2024-06-06T23:26:32.975382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, BitsAndBytesConfig, set_seed\n",
    "\n",
    "\n",
    "# Speciy model alias for HF\n",
    "alias =\"google/flan-t5-base\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(alias, trust_remote_code=True)\n",
    "\n",
    "#Quantization Config\n",
    "quant_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=False\n",
    ")\n",
    "\n",
    "# Load Model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    alias,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    "    quantization_config=quant_config\n",
    ")"
   ],
   "id": "3238c347c8a5c2f4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T23:38:07.452563Z",
     "start_time": "2024-06-06T23:38:07.322770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#load data\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from string import Template\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"ST1_data_processed_train.csv\")\n",
    "\n",
    "starting_text = \"Please Identify different types of claims(per_exp, claim_per_exp, question, claim, none) in the text:\"\n",
    "\n",
    "instruction_template = Template(\n",
    "\"\"\"\n",
    "# Instructions\n",
    "Given a text that may contain descriptions of personal experiences, questions, and claims, classify each segment into appropriate categories: 'per_exp' for personal experiences, 'claim_per_exp' for claims based on personal experiences, 'question' for any questions posed by the author, 'claim' for factual or general claims, and 'none' for segments that do not fit into the other categories. Analyze and categorize the text based on these labels to better understand the different elements of media communication.\"\n",
    "\n",
    "Example: \n",
    "Burning in chest with deep breath?\\nHey everyone. Diagnosed with gerd a few years back. \\nLatest issue i am having is it feels like someone is sitting on my chest at the top and the really annoying thing is burning in my chest with deep breaths. The burning is kinds constant in my throat but the deep breaths burning has me spooked.\\nHad an ekg a few months back, in 30 and relatively good health but sometimes these symptoms are so alarming especially to someone who has health anxiety. \\nI take rabeprazole when needed and gaviscon but this burning with deep breaths is what's scaring me. Anyone have that before and what did you find worked best?\\nThanks for any and all help!\n",
    "\n",
    "Answer:\n",
    "{\\'per_exp\\': [\\' Diagnosed with gerd a few years back. \\\\nLatest issue i am having is it feels like someone is sitting on my chest at the top and the really annoying thing is burning in my chest with deep breaths. The burning is kinds constant in my throat but the deep breaths burning has me spooked.\\\\n\\', \"\\\\nI take rabeprazole when needed and gaviscon but this burning with deep breaths is what\\'s scaring me\"], \\'claim_per_exp\\': [], \\'question\\': [\\' Anyone have that before and what did you find worked best?\\\\n\\'], \\'claim\\': [], \\'none\\': [\\'Burning in chest with deep breath?\\\\nHey everyone\\', \\'ad an ekg a few months back, in 30 and relatively good health but sometimes these symptoms are so alarming especially to someone who has health anxiety.\\', \\'hanks for any and all help\\']}\n",
    "\n",
    "\n",
    "Input\n",
    "$question\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "data[\"text\"] = data[\"text\"].apply(\n",
    "    lambda x: instruction_template.substitute({\"question\" : x})\n",
    ")\n",
    "\n",
    "\n",
    "data = Dataset.from_pandas(data)\n",
    "xx =data[0]\n",
    "# Define a size for your train set \n",
    "train_dataset = data.shuffle(seed=42).select(range(4556))\n",
    "test_dataset = data.shuffle(seed=42).select(range(4546, 4556))\n",
    "val_dataset = data.shuffle(seed=42).select(range(5126, 5695))\n",
    "\n",
    "\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T23:26:48.453532Z",
     "start_time": "2024-06-06T23:26:48.450002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers import AutoTokenizer, BatchEncoding\n",
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "# The collator is responsible for ensuring the generated batches have a fixed dimension as the \n",
    "#input will be tensor. \n",
    "\n",
    "@dataclass\n",
    "class SimpleCollator:\n",
    "    tokenizer: AutoTokenizer\n",
    "    config: dict \n",
    "    \n",
    "    def __call__(self, examples: list) -> dict:\n",
    "        batch = BatchEncoding(\n",
    "            {\n",
    "                k: [examples[i][k] for i in range(len(examples))]\n",
    "                for k, v in examples[0].items()\n",
    "            }\n",
    "        )\n",
    "\n",
    "        encoded_inputs = self.tokenizer(\n",
    "            batch[self.config[\"input_column\"]], \n",
    "            max_length = 128, \n",
    "            padding=True, \n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        encoded_targets = self.tokenizer(\n",
    "            batch[self.config[\"output_column\"]], max_length = 128, padding=True, truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        encoded_inputs[\"labels\"] = encoded_targets[\"input_ids\"]\n",
    "\n",
    "        return encoded_inputs\n",
    "\n",
    "collator = SimpleCollator(tokenizer, {\"input_column\": \"text\", \"output_column\": \"output_with_sentence\"})"
   ],
   "id": "7a69c3268c1705c0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T23:26:48.878785Z",
     "start_time": "2024-06-06T23:26:48.454478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM, \n",
    "    inference_mode=False, \n",
    "    target_modules=[\"q\", \"k\", \"v\"],\n",
    "    r=4, \n",
    "    lora_alpha=32, \n",
    "    lora_dropout=0.5\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)"
   ],
   "id": "c836fc496d2b1388",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T23:26:48.884513Z",
     "start_time": "2024-06-06T23:26:48.880167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Note that the trainable parameters are signifacntly smaller. We only training 24% of the model!\n",
    "model.print_trainable_parameters()"
   ],
   "id": "5e8958023fb3d8df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 663,552 || all params: 248,241,408 || trainable%: 0.2673\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T23:26:48.888476Z",
     "start_time": "2024-06-06T23:26:48.885506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Prepare Dataloaders\n",
    "train_dl = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=4,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    "    collate_fn=collator\n",
    ")\n",
    "\n",
    "val_dl = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    "    collate_fn=collator\n",
    ")\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=16,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    "    collate_fn=collator\n",
    ")"
   ],
   "id": "ba74f87ab95d9464",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T23:26:49.380984Z",
     "start_time": "2024-06-06T23:26:48.889243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tqdm.notebook as tqdm\n",
    "\n",
    "\n",
    "\n",
    "all_preds = []\n",
    "for batch in tqdm.tqdm(test_dl, total = len(test_dl)):\n",
    "    \n",
    "    preds = model.generate(**batch, max_new_tokens=128)\n",
    "    outputs = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    all_preds.extend(outputs)\n",
    "\n",
    "# Note the FlAN T5 model ignores our instruction format and procuces the letters for prediction\n",
    "all_preds"
   ],
   "id": "f8974efec9de682d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48bebf6fdc2541f1881a9cd4ee15bc42"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zixian/.conda/envs/ctr-ai_training/lib/python3.8/site-packages/transformers/generation/utils.py:1659: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['one', 'one']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T23:26:58.192598Z",
     "start_time": "2024-06-06T23:26:49.381792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import lightning as pl\n",
    "from torch.optim import AdamW\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "class PeftCALMT5(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model_alias: str, tokenizer_alias: str):\n",
    "\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_alias)\n",
    "\n",
    "        self.peft_config = LoraConfig(\n",
    "            task_type=TaskType.SEQ_2_SEQ_LM, \n",
    "            inference_mode=False, \n",
    "            target_modules=[\"q\", \"k\", \"v\"],\n",
    "            r=4, \n",
    "            lora_alpha=32, \n",
    "            lora_dropout=0.5\n",
    "        )\n",
    "\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(model_alias)\n",
    "        self.model = get_peft_model(model, self.peft_config)\n",
    "        \n",
    "\n",
    "    def training_step(self, batch, batch_idx): \n",
    "        outputs = self.model.forward(**batch, return_dict=True)\n",
    "        loss = outputs[\"loss\"]  \n",
    "        \n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=True, on_epoch=True)     \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs = self.model(**batch)\n",
    "        loss = outputs[\"loss\"]  \n",
    "        \n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True) \n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.model.parameters(), lr=5e-4)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "model = PeftCALMT5(model_alias=alias, tokenizer_alias=alias)"
   ],
   "id": "15b1a9c66d5ba8ce",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T23:29:01.229160Z",
     "start_time": "2024-06-06T23:26:58.193669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = pl.Trainer(\n",
    "  max_epochs=1,\n",
    "  devices=1, \n",
    "  accelerator=\"gpu\",\n",
    "  accumulate_grad_batches=3#Note we accumlate batches to effective form larger training batches \n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dl, val_dl)"
   ],
   "id": "a0f5a3c92c65f5e6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/zixian/.conda/envs/ctr-ai_training/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                  | Params\n",
      "------------------------------------------------\n",
      "0 | model | PeftModelForSeq2SeqLM | 248 M \n",
      "------------------------------------------------\n",
      "663 K     Trainable params\n",
      "247 M     Non-trainable params\n",
      "248 M     Total params\n",
      "992.966   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "806ce170433741a98adb4858dac5feba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zixian/.conda/envs/ctr-ai_training/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/zixian/.conda/envs/ctr-ai_training/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/zixian/.conda/envs/ctr-ai_training/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a44ec28195345d184d91dc6c675ed98"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "217d73a2c5ac47d4bc115e50d18cba2c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T23:38:21.353974Z",
     "start_time": "2024-06-06T23:38:12.146101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ft_preds = []\n",
    "test_dl = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=16,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    "    collate_fn=collator\n",
    ")\n",
    "source = []\n",
    "for batch in tqdm.tqdm(test_dl, total = len(test_dl)):\n",
    "    preds = model.model.generate(**batch, max_new_tokens=256)\n",
    "    outputs = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    outputs_source = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)\n",
    "\n",
    "    ft_preds.extend(outputs)\n",
    "    source.extend(outputs_source)\n",
    "# ft_preds[:]\n",
    "print(source[:])\n",
    "print(\"*\"*20)\n",
    "print(ft_preds[:])\n",
    "# source['labels']"
   ],
   "id": "df655ac99306db62",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "814a8524134d4687abc8a08ad208012b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'per_exp': [' recently been diagnosed and just finishing my 3rd flare (2nd in 5 weeks) nI have been prescribed 100mg of Allo', 'nI am currently at the stage where my big toe just feels bruised which lasted around another 2 weeks after i considered my last flare finished last time.'], 'claim_per_exp': [], 'question': [' when is best to start it', 'nDo I need to wait until its completely gone?'], \", '\\'per_exp\\': [\\'Cough induced Lower Oblique Hematoma - who knew!!!!!\\', \"nI had a pretty decent exacerbation the first of the month. During a coughing fit and felt a hot sharp pain in my lower right side. It gradually went away, then during airway clearance this last weekend it happened again only this time with a vengeance. a couple days later I noticed a HUGE deep black bruise on my side. Google Cough Induced Lower Oblique Hematoma', '\\'per_exp\\': [\" my doctor mentioned recently that compression shorts also could help, and I\\'m a little bit skeptical because I always thought it needed to be full leg or abdominal compression, however, it got me thinking. I know underworks has high compression shorts and underwear to help reduce the appearance of the butt and hips for trans folks. I could never really justify buying them previously, but what if they could help both with my hips and my POTS\", \" I\\'d hate to waste my money on em if they\\'re unlikely to', \"'per_exp': [], 'claim_per_exp': ['nFoods that trigger me n-garlic n-onionsn-sauces n-red meat n-veggies such as broccoli cauliflower nLactose as well so icecream, basically anything dairy'], 'question': ['What foods dont trigger you at all?'], 'claim': [], 'none': ['I have been trying to find things to e\", '\\'per_exp\\': [\" I\\'m looking for advice and recommendations as my son (14) had his 2nd seizure yesterday. His first seizure was 3 years ago. \",\\'So yesterday I was very surprised when he had a grand mal seizure lasting just under 5 minutes\\', \" Afterwards it took 15 minutes before he recognized us. Today, 24 hours later he says his legs feel like they have 50 lbs on them, he\\'s unsteady when standing or walking, his face is swollen, he', \"'per_exp': ['nI have just started Kaftrio 2 weeks ago and I am struggling a bit in rearranging the correct dosage of Creon. '], 'claim_per_exp': [], 'question': ['How did you rearrange your Creon after starting Kaftrio?','What was your experience? ','Do you need more or less Creon now? ','What did you do to identify the new correct dosage for you?'], 'claim\", \"'per_exp': ['e. I am having a flare', 'nI need the infusion now to stop the flare'], 'claim_per_exp': [], 'question': [' What do I do? Does anyone know of a neurologist here that is responsive and acts quickly when it comes to addressing attacks? '], 'claim': [], 'none': ['Full on Flare in a New State - OK - and In Need of a\", \"'per_exp': ['n[deleted]'], 'claim_per_exp': [], 'question': [''], 'claim': [], 'none': ['Cold weather causing scalp blister', '']\", '\\'per_exp\\': [\\' It is terrifying and exhausting\\'], \\'claim_per_exp\\': [], \\'question\\': [\\'Can anyone relate?\\', \\'nDoes anyone relate to this?\\',\\'How the hell am I supposed to stay calm without reminding myself about everything in existence at the same time at every second?\\'], \\'claim\\': [], \\'none\\': [\"The only way I can describe what\\'s going on is that I feel like the universe is playing peek-a-', \"'per_exp': ['nI have had a headache for 2 weeks and sleep for over half the weekend to try and catch up because I am so exhausted but for the first time ever all my blood work is coming back completely normal'], 'claim_per_exp': [], 'question': [], 'claim': [], 'none': ['Annoyed with bloodwor','It makes no sense!nnEdit: fixed a typo']\"]\n",
      "********************\n",
      "[\"'per_exp': ['nI have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have \", \"'per_exp': ['nI've been having a lot of issues with my gout','I've had a lot of issues with my gout','I've had a lot of issues with my gout','I've had a lot of issues with my gout','I've had a lot of issues with my gout','I've had a lot of issues with my gout'], 'claim_per_exp': [], 'question': ['nIs there any way to get a gout cure?', 'nI've had a lot of issues with my gout','I've had a lot of issues with my gout','I've had a lot of issues with my gout','I've had a lot of issues with my gout','I've had a lot of issues with my gout','I've had\", \"'per_exp': ['', ''], 'claim_per_exp': [], 'question': [''], 'claim': [], 'none': ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\", \"'per_exp': ['nI've been having a lot of issues with my phlegm lately','I've been having a lot of issues with my phlegm lately','I've been having a lot of issues with my phlegm lately','I've been having a lot of issues with my phlegm lately','I've been having a lot of issues with my phlegm lately'], 'claim_per_exp'\", \"'per_exp': ['nI've been having a lot of issues with my phlegm and my phlegm is a bit swollen and it's a bit swollen','I've been having a lot of issues with my phlegm and my phlegm is a bit swollen and it's a bit swollen','I've been having a lot of issues with my phlegm and my phlegm is a bit swollen and it's a bit swollen and it's a bit swollen and it's a bit swollen and it's a bit swollen and it's a bit swollen and it's a bit swollen and it's a bit swollen and it's a bit swollen and it's a bit swollen and it's a bit swollen and it's a bit\", \"'per_exp': ['nI have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have \", \"'per_exp': ['nI've been having a lot of issues with my syphilis and my syphilis has been getting worse. I've been having a lot of issues with my syphilis and my syphilis has been getting worse.'], 'claim_per_exp': [], 'question': ['nAnyone else have a similar experience?'], 'claim': [], 'none': ['I'm a syphilis sufferer and I've had a lot of issues with my syphilis and my syphilis']\", \"'per_exp': ['nI have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have a strep throat and I have a strep throat. I have \", \"'per_exp': ['nI have been having a lot of issues with my spleen and I have been having a lot of issues with my spleen. I have been having a lot of issues with my spleen and I have been having a lot of issues with my spleen and I have been having a lot of issues with my spleen and I have been having a lot of issues with my spleen and I have been having a lot of issues with my spleen and I have been having a lot of issues with my spleen and I have been having a lot of issues with my spleen and I have been having a lot of issues with my spleen and I have been having a lot of issues with my spleen and I have been having a lot of issues with my spleen and I have been having a lot of issues with my spleen and I have been having a lot of issues with my spleen and I have been having a lot of issues with my spleen and I have been\", \"'per_exp': ['nI've been having a lot of issues with my syphilis and my syphilis is a very serious problem. I have been having a lot of issues with my syphilis and my syphilis is a very serious problem.','I have been having a lot of issues with my syphilis and my syphilis is a very serious problem.'], 'claim_per_exp': [], 'question': ['nIs there anything else I can do to help?', 'n\"]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T23:29:04.824133Z",
     "start_time": "2024-06-06T23:29:04.822721Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d2fc958e6dc11443",
   "outputs": [],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
